{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"About LPBenchGen is an OWL explainable structural learning problem Benchmark Generator. Explainable AI is becoming more important and more and more systems to tackle that problem are developed. However, there is a lack of benchmark datasets. LPBenchGen tries to tackle that problem by providing a tool that can generate benchmarks using a TBox and an ABox. The ABox can either be behind a SPARQL endpoint or in an RDF file. Using an RDF file allows an Open World Assumption. This is restricted in SPARQL, which generally allows only a Closed World Assumption. What is a Learning Problem in this context? A learning problem is a set of positive examples and negative examples, whereas one example is an Individual contained in the ABox. A system then may be benchmarked to find the best concept/class expression or try to find all other positive Individuals . How does it work? LPBenchGen will create a lot of theoretically class expression based upon the TBox and checks if these have enough solutions using the ABox. The user can set parameters allowing longer and more complex as well as smaller and easier expressions, how many of these should be created and a lot more. Using these expressions LPBenchGen creates positive examples for one learning problem. However, it is not straight forward to retrieve negative examples. For example if we have a big diverse Database and have a concept such as Tree and (hasLeaves some Leaves) : A negative Example such as Elefant wouldn't be useful at all. What would be useful is something like WindFlower-1 as it has leaves, but is not a Tree. Hence, LPBenchGen creates a few class expression based upon the positive class expressions in that matter. These basically negate some parts of the original expression and hence providing useful negative examples. Afterwards these concepts will be used to retrieve positive and negative examples and thus creating the learning problem. A benchmark in this context is a set of such learning problems. For a detailed description please have a look at Underlying-Model What does LPBenchGen generate? LPBenchGen generates a training benchmark set, a test benchmark set and a gold standard for the test benchmark. My ABox is huge, no current system can work with that! No worries. LPBenchGen can create a small ABox fitting the problems in the benchmark. How do I evaluate my system? If you generated your benchmark accordingly (see Usage) LPBenchGen provides a small evaluation. Simply use the test benchmark, the gold standard, and the actual system answers and evaluate. See Usage for the correct format and eval. How to download Download the latest release jar file at https://github.com/dice-group/LPBenchGen/releases/latest See Getting-Started for how to execute the generation. Where can I find the code? The code is open source at https://github.com/dice-group/LPBenchGen and you can code with us if you want to :) Where do I submit a bug or enhancement? Please use the Github Issue Tracker at https://github.com/dice-group/LPBenchGen/issues","title":"About"},{"location":"#about","text":"LPBenchGen is an OWL explainable structural learning problem Benchmark Generator. Explainable AI is becoming more important and more and more systems to tackle that problem are developed. However, there is a lack of benchmark datasets. LPBenchGen tries to tackle that problem by providing a tool that can generate benchmarks using a TBox and an ABox. The ABox can either be behind a SPARQL endpoint or in an RDF file. Using an RDF file allows an Open World Assumption. This is restricted in SPARQL, which generally allows only a Closed World Assumption.","title":"About"},{"location":"#what-is-a-learning-problem-in-this-context","text":"A learning problem is a set of positive examples and negative examples, whereas one example is an Individual contained in the ABox. A system then may be benchmarked to find the best concept/class expression or try to find all other positive Individuals .","title":"What is a Learning Problem in this context?"},{"location":"#how-does-it-work","text":"LPBenchGen will create a lot of theoretically class expression based upon the TBox and checks if these have enough solutions using the ABox. The user can set parameters allowing longer and more complex as well as smaller and easier expressions, how many of these should be created and a lot more. Using these expressions LPBenchGen creates positive examples for one learning problem. However, it is not straight forward to retrieve negative examples. For example if we have a big diverse Database and have a concept such as Tree and (hasLeaves some Leaves) : A negative Example such as Elefant wouldn't be useful at all. What would be useful is something like WindFlower-1 as it has leaves, but is not a Tree. Hence, LPBenchGen creates a few class expression based upon the positive class expressions in that matter. These basically negate some parts of the original expression and hence providing useful negative examples. Afterwards these concepts will be used to retrieve positive and negative examples and thus creating the learning problem. A benchmark in this context is a set of such learning problems. For a detailed description please have a look at Underlying-Model","title":"How does it work?"},{"location":"#what-does-lpbenchgen-generate","text":"LPBenchGen generates a training benchmark set, a test benchmark set and a gold standard for the test benchmark.","title":"What does LPBenchGen generate?"},{"location":"#my-abox-is-huge-no-current-system-can-work-with-that","text":"No worries. LPBenchGen can create a small ABox fitting the problems in the benchmark.","title":"My ABox is huge, no current system can work with that!"},{"location":"#how-do-i-evaluate-my-system","text":"If you generated your benchmark accordingly (see Usage) LPBenchGen provides a small evaluation. Simply use the test benchmark, the gold standard, and the actual system answers and evaluate. See Usage for the correct format and eval.","title":"How do I evaluate my system?"},{"location":"#how-to-download","text":"Download the latest release jar file at https://github.com/dice-group/LPBenchGen/releases/latest See Getting-Started for how to execute the generation.","title":"How to download"},{"location":"#where-can-i-find-the-code","text":"The code is open source at https://github.com/dice-group/LPBenchGen and you can code with us if you want to :)","title":"Where can I find the code?"},{"location":"#where-do-i-submit-a-bug-or-enhancement","text":"Please use the Github Issue Tracker at https://github.com/dice-group/LPBenchGen/issues","title":"Where do I submit a bug or enhancement?"},{"location":"Getting-Started/","text":"Download Prerequisites You need to have Java 11 or higher installed. In Ubuntu you can do this by sudo apt-get install java Download To download LPBenchGen get the latest release here . wget https://github.com/dice-group/LPBenchGen/releases/download/v2.0.1/lpbenchgen-2.0.1.jar","title":"Download"},{"location":"Getting-Started/#download","text":"","title":"Download"},{"location":"Getting-Started/#prerequisites","text":"You need to have Java 11 or higher installed. In Ubuntu you can do this by sudo apt-get install java","title":"Prerequisites"},{"location":"Getting-Started/#download_1","text":"To download LPBenchGen get the latest release here . wget https://github.com/dice-group/LPBenchGen/releases/download/v2.0.1/lpbenchgen-2.0.1.jar","title":"Download"},{"location":"Getting-Started/Quick-Configuration/","text":"Quick Configuration The easiest configuration you can do is ### THE ABOX endpoint: /path/to/your/ABOX-rdf-file.ttl # you can also use a sparql endpoint #endpoint: http://your.endpoint/sparql ### THE TBOX owlFile: /path/to/your/ontology.owl For further information see Configuration","title":"Quick Configuration"},{"location":"Getting-Started/Quick-Configuration/#quick-configuration","text":"The easiest configuration you can do is ### THE ABOX endpoint: /path/to/your/ABOX-rdf-file.ttl # you can also use a sparql endpoint #endpoint: http://your.endpoint/sparql ### THE TBOX owlFile: /path/to/your/ontology.owl For further information see Configuration","title":"Quick Configuration"},{"location":"Getting-Started/Run-LPBenchGen/","text":"Generate a Benchmark To generate a Benchmark execute the following. java -jar lpbenchgen-2.0.1.jar --name YOUR_BENCHMARK_NAME --config /PATH/TO/YOUR/CONFIG.yml --format rdf if you want to get the benchmark in RDF. If you want to use JSON exchange --format rdf to --format json Additional you can generate a small ABox fitting to the benchmark by adding --generate-abox java -jar lpbenchgen-2.0.1.jar --name YOUR_BENCHMARK_NAME --config /PATH/TO/YOUR/CONFIG.yml --format rdf --generate-abox","title":"Generate a Benchmark"},{"location":"Getting-Started/Run-LPBenchGen/#generate-a-benchmark","text":"To generate a Benchmark execute the following. java -jar lpbenchgen-2.0.1.jar --name YOUR_BENCHMARK_NAME --config /PATH/TO/YOUR/CONFIG.yml --format rdf if you want to get the benchmark in RDF. If you want to use JSON exchange --format rdf to --format json Additional you can generate a small ABox fitting to the benchmark by adding --generate-abox java -jar lpbenchgen-2.0.1.jar --name YOUR_BENCHMARK_NAME --config /PATH/TO/YOUR/CONFIG.yml --format rdf --generate-abox","title":"Generate a Benchmark"},{"location":"Underlying-Model/","text":"Concept Generation In this section we will explain how LPBenchGen generates positive as well as negative class expressions/concepts. Positive Concept Generation A positive concept (a class expression used for the retrieval of positive examples) is generated recursively. It depends on the minimum and maximum concept length, the maximum recursive depth, negative mutation ratio (see below) and if lateral combinations should be used (see below). The positive concept generation uses all allowed types in the ontology and creates concepts for each class type A as follows: Add A get all property assertions where A is domain (or where a super class of A is the domain). for all of them add A hasRule some B , whereas B is the range class (or a subtype of the range class) if depth<maxDepth: go to step 2 but use B instead of A . get all concepts for B and create for all of them A and hasRule some C , whereas C represents the class expressions returned by B. get all property assertions where A is range (or where a super class of A is the range class). for all of them add hasRule some A go to step 2 and instead of adding A and hasRule some C , add hasRule some (A and hasOtherRule some C) Finally, only concepts fitting the minimum and maximum concept length will be accepted. Negative Mutations At each recursive step a negative mutation of the current class expression can be added as well. This will simply negate the current expression like not C whereas C is a class expression. This is done using a negative mutation ratio [0,1]. A random double will be retrieved and if the random is smaller or equal to the ratio, a negative mutation will be added. Example: Let's have A as a start expression and hasRule some B in the first recursive step and let the ratio be 1 , hence always creates a negative mutation. In the first step the start expression A would be negated as not A and both A as well as not A would be added. The algorithm would create not (hasRule some B) in the first recursion and returns both not (hasRule some B) and hasRule some B . Afterwards the combination will take place using A and not A . This will lead to the following final class expressions: A and hasRule some B , A and not (hasRule some B) , not A and hasRule some B and not A and not (hasRule some B) . Negative Concept Generation For each positive class expression, several negative expressions can be created. This is done to assure good negative examples, as these negative expressions are still linked to the original expression, and in most cases contain more information rather random retrieval. Note: a single Class like A will be negated to not A which basically is the same as a random retrieval. The expression will be negated recursively as follows ( A and B simple classes, C and D are complex expressions): original expression negated expressions A not A C and D not (C and D) , C and not D , not C and D C or D not (C or D) not C C hasRule some C hasRule only not C hasRule only C hasRule some not C Every other expression such as max cardinality will be non recursively negated. Open World vs Closed World Assumption LPBenchGen supports both the Open World Assumption and the Closed World Assumption. If you're using a SPARQL endpoint the OWA is restricted though, as we cannot reason completely using SPARQL and hence need to reason later on. This step requires the ABox generation and examples which are either False Positive or False negative will be removed from the learning problem. If you're using an RDF file however, you can choose between both. The Open World Assumption uses the awesome and fast Openllet Reasoner you can find here","title":"Concept Generation"},{"location":"Underlying-Model/#concept-generation","text":"In this section we will explain how LPBenchGen generates positive as well as negative class expressions/concepts.","title":"Concept Generation"},{"location":"Underlying-Model/#positive-concept-generation","text":"A positive concept (a class expression used for the retrieval of positive examples) is generated recursively. It depends on the minimum and maximum concept length, the maximum recursive depth, negative mutation ratio (see below) and if lateral combinations should be used (see below). The positive concept generation uses all allowed types in the ontology and creates concepts for each class type A as follows: Add A get all property assertions where A is domain (or where a super class of A is the domain). for all of them add A hasRule some B , whereas B is the range class (or a subtype of the range class) if depth<maxDepth: go to step 2 but use B instead of A . get all concepts for B and create for all of them A and hasRule some C , whereas C represents the class expressions returned by B. get all property assertions where A is range (or where a super class of A is the range class). for all of them add hasRule some A go to step 2 and instead of adding A and hasRule some C , add hasRule some (A and hasOtherRule some C) Finally, only concepts fitting the minimum and maximum concept length will be accepted.","title":"Positive Concept Generation"},{"location":"Underlying-Model/#negative-mutations","text":"At each recursive step a negative mutation of the current class expression can be added as well. This will simply negate the current expression like not C whereas C is a class expression. This is done using a negative mutation ratio [0,1]. A random double will be retrieved and if the random is smaller or equal to the ratio, a negative mutation will be added. Example: Let's have A as a start expression and hasRule some B in the first recursive step and let the ratio be 1 , hence always creates a negative mutation. In the first step the start expression A would be negated as not A and both A as well as not A would be added. The algorithm would create not (hasRule some B) in the first recursion and returns both not (hasRule some B) and hasRule some B . Afterwards the combination will take place using A and not A . This will lead to the following final class expressions: A and hasRule some B , A and not (hasRule some B) , not A and hasRule some B and not A and not (hasRule some B) .","title":"Negative Mutations"},{"location":"Underlying-Model/#negative-concept-generation","text":"For each positive class expression, several negative expressions can be created. This is done to assure good negative examples, as these negative expressions are still linked to the original expression, and in most cases contain more information rather random retrieval. Note: a single Class like A will be negated to not A which basically is the same as a random retrieval. The expression will be negated recursively as follows ( A and B simple classes, C and D are complex expressions): original expression negated expressions A not A C and D not (C and D) , C and not D , not C and D C or D not (C or D) not C C hasRule some C hasRule only not C hasRule only C hasRule some not C Every other expression such as max cardinality will be non recursively negated.","title":"Negative Concept Generation"},{"location":"Underlying-Model/#open-world-vs-closed-world-assumption","text":"LPBenchGen supports both the Open World Assumption and the Closed World Assumption. If you're using a SPARQL endpoint the OWA is restricted though, as we cannot reason completely using SPARQL and hence need to reason later on. This step requires the ABox generation and examples which are either False Positive or False negative will be removed from the learning problem. If you're using an RDF file however, you can choose between both. The Open World Assumption uses the awesome and fast Openllet Reasoner you can find here","title":"Open World vs Closed World Assumption"},{"location":"Underlying-Model/ABox-Generation/","text":"ABox Generation The ABox generation allows to generate a smaller ABox which includes all Individuals in the train and gold standard benchmark. The generation assures that all Individuals in the smaller ABox still have all relations that they need to assure to be considered a positive example if they are and a negative if they're not. In general the ABox will consist of the TBox as a base and then uses the ABox to retrieve these relations (Triples) via SPARQL and add them to the ABox. Individual Retrieval For each Learning Problem, for each Individual (positive as negative) the process to retrieve their necessary triples is as follows: The corresponding OWL Class Expression will be translated to SPARQL using a slightly adjusted variant of SmartDataAnalytics OWL2SPARQL . The root variable will be exchanged with the current Individual (which we want to retrieve triples for) Then we will set all occurring variables as project variables. For each triple pattern in the query which does not contain a variable, LPBenchGen simply adds that triple to the ABox. For each triple pattern containing a variable, LPBenchGen exchanges that variable by the query solution bindings and add that triple to the ABox. Example The concept: A and (hasRule some B) The SPARQL query: SELECT ?var {?var a A ; hasRule ?s0 . ?s0 a B . } The Individuals for this concept: http://example.com/Individual1 , http://example.com/Individual2 ,... Then for each Individual we will do the following: Exchange the query: SELECT {<http://example.com/Individual1> a A ; hasRule ?s0 . ?s0 a B . } set all remaining vars as projection vars: SELECT ?s0 {<http://example.com/Individual1> a A ; hasRule ?s0 . ?s0 a B . } set a limit (user defined) for efficiency: SELECT ?s0 {<http://example.com/Individual1> a A ; hasRule ?s0 . ?s0 a B . } LIMIT 100 Retrieve results to a ResultSet Create Triples: Add triple for all non variable triples in the query: In this case: <http://example.com/Individual1> rdf:type A And create triples from Results for every triple in the query: for(QueryBinding result : ResultSet){ addTriple(<http://example.com/Individual1> hasRule result[?s0]); addTriple(result[?s0] rdf:type B); }","title":"ABox Generation"},{"location":"Underlying-Model/ABox-Generation/#abox-generation","text":"The ABox generation allows to generate a smaller ABox which includes all Individuals in the train and gold standard benchmark. The generation assures that all Individuals in the smaller ABox still have all relations that they need to assure to be considered a positive example if they are and a negative if they're not. In general the ABox will consist of the TBox as a base and then uses the ABox to retrieve these relations (Triples) via SPARQL and add them to the ABox.","title":"ABox Generation"},{"location":"Underlying-Model/ABox-Generation/#individual-retrieval","text":"For each Learning Problem, for each Individual (positive as negative) the process to retrieve their necessary triples is as follows: The corresponding OWL Class Expression will be translated to SPARQL using a slightly adjusted variant of SmartDataAnalytics OWL2SPARQL . The root variable will be exchanged with the current Individual (which we want to retrieve triples for) Then we will set all occurring variables as project variables. For each triple pattern in the query which does not contain a variable, LPBenchGen simply adds that triple to the ABox. For each triple pattern containing a variable, LPBenchGen exchanges that variable by the query solution bindings and add that triple to the ABox.","title":"Individual Retrieval"},{"location":"Underlying-Model/ABox-Generation/#example","text":"The concept: A and (hasRule some B) The SPARQL query: SELECT ?var {?var a A ; hasRule ?s0 . ?s0 a B . } The Individuals for this concept: http://example.com/Individual1 , http://example.com/Individual2 ,... Then for each Individual we will do the following: Exchange the query: SELECT {<http://example.com/Individual1> a A ; hasRule ?s0 . ?s0 a B . } set all remaining vars as projection vars: SELECT ?s0 {<http://example.com/Individual1> a A ; hasRule ?s0 . ?s0 a B . } set a limit (user defined) for efficiency: SELECT ?s0 {<http://example.com/Individual1> a A ; hasRule ?s0 . ?s0 a B . } LIMIT 100 Retrieve results to a ResultSet Create Triples: Add triple for all non variable triples in the query: In this case: <http://example.com/Individual1> rdf:type A And create triples from Results for every triple in the query: for(QueryBinding result : ResultSet){ addTriple(<http://example.com/Individual1> hasRule result[?s0]); addTriple(result[?s0] rdf:type B); }","title":"Example"},{"location":"Underlying-Model/Output-Formats/","text":"Output Formats The train/test/gold standard datasets can be stored either as json or RDF/Turtle. JSON train [ { \"concept\": \"Album and (artist some dul:Agent)\", \"positives\": [ \"http://example.com/positiveIndividual1\", \"http://example.com/positiveIndividual2\", ... \"http://example.com/positiveIndividualN\" ], \"negatives\": [ \"http://example.com/negativeIndividual1\", \"http://example.com/negativeIndividual2\", ... \"http://example.com/negativeIndividualM\" ] }, ... ] test [ { \"positives\": [ \"http://example.com/positiveIndividual1\", \"http://example.com/positiveIndividual2\", ... \"http://example.com/positiveIndividualN\" ], \"negatives\": [ \"http://example.com/negativeIndividual1\", \"http://example.com/negativeIndividual2\", ... \"http://example.com/negativeIndividualM\" ] }, ... ] gold standard [ { \"concept\": \"Album and (artist some dul:Agent)\", \"positives\": [ \"http://example.com/positiveIndividual1\", \"http://example.com/positiveIndividual2\", ... \"http://example.com/positiveIndividualN\" ] }, ... ] RDF/TURTLE train @prefix lpclass: <https://lpbenchgen.org/class/> . @prefix lpres: <https://lpbenchgen.org/resource/> . @prefix lpprop: <https://lpbenchgen.org/property/> . @prefix example: <https://example.com> . lpres:lp_1 rdf:type lpclass:LearningProblem ; lpprop:concept \"example:A\\n and (example:hasRule some example:B)\" ; lpprop:includesResource example:positiveIndividual-1 , example:positiveIndividual-2, ... . lpprop:excludesResource example:negativeIndividual-1 , example:negativeIndividual-2, ... . ... test @prefix lpclass: <https://lpbenchgen.org/class/> . @prefix lpres: <https://lpbenchgen.org/resource/> . @prefix lpprop: <https://lpbenchgen.org/property/> . @prefix example: <https://example.com> . lpres:lp_1 rdf:type lpclass:LearningProblem ; lpprop:includesResource example:positiveIndividual-1 , example:positiveIndividual-2 . lpprop:excludesResource example:negativeIndividual-1 , example:negativeIndividual-2 . ... gold standard @prefix lpclass: <https://lpbenchgen.org/class/> . @prefix lpres: <https://lpbenchgen.org/resource/> . @prefix lpprop: <https://lpbenchgen.org/property/> . @prefix example: <https://example.com> . lpres:lp_1 rdf:type lpclass:LearningProblem ; lpprop:concept \"example:A\\n and (example:hasRule some example:B)\" ; lpprop:includesResource example:positiveIndividual-1 , example:positiveIndividual-2, ... . ...","title":"Output Formats"},{"location":"Underlying-Model/Output-Formats/#output-formats","text":"The train/test/gold standard datasets can be stored either as json or RDF/Turtle.","title":"Output Formats"},{"location":"Underlying-Model/Output-Formats/#json","text":"","title":"JSON"},{"location":"Underlying-Model/Output-Formats/#train","text":"[ { \"concept\": \"Album and (artist some dul:Agent)\", \"positives\": [ \"http://example.com/positiveIndividual1\", \"http://example.com/positiveIndividual2\", ... \"http://example.com/positiveIndividualN\" ], \"negatives\": [ \"http://example.com/negativeIndividual1\", \"http://example.com/negativeIndividual2\", ... \"http://example.com/negativeIndividualM\" ] }, ... ]","title":"train"},{"location":"Underlying-Model/Output-Formats/#test","text":"[ { \"positives\": [ \"http://example.com/positiveIndividual1\", \"http://example.com/positiveIndividual2\", ... \"http://example.com/positiveIndividualN\" ], \"negatives\": [ \"http://example.com/negativeIndividual1\", \"http://example.com/negativeIndividual2\", ... \"http://example.com/negativeIndividualM\" ] }, ... ]","title":"test"},{"location":"Underlying-Model/Output-Formats/#gold-standard","text":"[ { \"concept\": \"Album and (artist some dul:Agent)\", \"positives\": [ \"http://example.com/positiveIndividual1\", \"http://example.com/positiveIndividual2\", ... \"http://example.com/positiveIndividualN\" ] }, ... ]","title":"gold standard"},{"location":"Underlying-Model/Output-Formats/#rdfturtle","text":"","title":"RDF/TURTLE"},{"location":"Underlying-Model/Output-Formats/#train_1","text":"@prefix lpclass: <https://lpbenchgen.org/class/> . @prefix lpres: <https://lpbenchgen.org/resource/> . @prefix lpprop: <https://lpbenchgen.org/property/> . @prefix example: <https://example.com> . lpres:lp_1 rdf:type lpclass:LearningProblem ; lpprop:concept \"example:A\\n and (example:hasRule some example:B)\" ; lpprop:includesResource example:positiveIndividual-1 , example:positiveIndividual-2, ... . lpprop:excludesResource example:negativeIndividual-1 , example:negativeIndividual-2, ... . ...","title":"train"},{"location":"Underlying-Model/Output-Formats/#test_1","text":"@prefix lpclass: <https://lpbenchgen.org/class/> . @prefix lpres: <https://lpbenchgen.org/resource/> . @prefix lpprop: <https://lpbenchgen.org/property/> . @prefix example: <https://example.com> . lpres:lp_1 rdf:type lpclass:LearningProblem ; lpprop:includesResource example:positiveIndividual-1 , example:positiveIndividual-2 . lpprop:excludesResource example:negativeIndividual-1 , example:negativeIndividual-2 . ...","title":"test"},{"location":"Underlying-Model/Output-Formats/#gold-standard_1","text":"@prefix lpclass: <https://lpbenchgen.org/class/> . @prefix lpres: <https://lpbenchgen.org/resource/> . @prefix lpprop: <https://lpbenchgen.org/property/> . @prefix example: <https://example.com> . lpres:lp_1 rdf:type lpclass:LearningProblem ; lpprop:concept \"example:A\\n and (example:hasRule some example:B)\" ; lpprop:includesResource example:positiveIndividual-1 , example:positiveIndividual-2, ... . ...","title":"gold standard"},{"location":"Usage/","text":"Usage In this section we'll explain how to use LPBenchGen. Have a look at Configuration to understand how to configure the generation, and have a look at Evaluation to find out how to evaluate your system using LPBenchGen. Generate Benchmark To generate a Benchmark execute the following. java -jar lpbenchgen-2.0.1.jar --name YOUR_BENCHMARK_NAME --config /PATH/TO/YOUR/CONFIG.yml --format rdf if you want to get the benchmark in RDF. If you want to use JSON exchange --format rdf to --format json Additional you can generate a small ABox fitting to the benchmark by adding --generate-abox java -jar lpbenchgen-2.0.1.jar --name YOUR_BENCHMARK_NAME --config /PATH/TO/YOUR/CONFIG.yml --format rdf --generate-abox JavaDoc The JavaDoc can be found at here","title":"Usage"},{"location":"Usage/#usage","text":"In this section we'll explain how to use LPBenchGen. Have a look at Configuration to understand how to configure the generation, and have a look at Evaluation to find out how to evaluate your system using LPBenchGen.","title":"Usage"},{"location":"Usage/#generate-benchmark","text":"To generate a Benchmark execute the following. java -jar lpbenchgen-2.0.1.jar --name YOUR_BENCHMARK_NAME --config /PATH/TO/YOUR/CONFIG.yml --format rdf if you want to get the benchmark in RDF. If you want to use JSON exchange --format rdf to --format json Additional you can generate a small ABox fitting to the benchmark by adding --generate-abox java -jar lpbenchgen-2.0.1.jar --name YOUR_BENCHMARK_NAME --config /PATH/TO/YOUR/CONFIG.yml --format rdf --generate-abox","title":"Generate Benchmark"},{"location":"Usage/#javadoc","text":"The JavaDoc can be found at here","title":"JavaDoc"},{"location":"Usage/Configuration/","text":"Configuration In this section we'll explain how to configure the generation of a learning problem benchmark. Ways to Generate a Benchmark There are 3 main ways to generate a LP benchmark. The first one is to use a gold standard positive concept, which represents one learning problem and furthermore provide concepts which won't fit the positive concept (we call them negative concepts wrt a positive concept). This negative concept should be close to the positive one but yield other individuals. e.g. Politician and hasParents some Person can have multiple negative concepts such as not Politician and hasParents some Person and Politician and not (hasParents some Person) while the latter obv. wouldn't yield results. However, it might be a lot of work to add for all positive concepts multiple useful negative concepts. Hence, LPBenchGen can generate negative concepts out of positives, and you only provide positive concepts You can also just let LPBenchGen generate concepts from the TBox and ABox. It will first generate all possible concepts in the parameters provided by the configuration, and then check if these concepts yields enough results using the ABox. Allowing certain types to yield a topical subset of the ABox. Further on you can add allowed Types. This will be used to only allow Individuals who have a class of this type To generate positive concepts only considering these types. Methods of generating a Benchmark General Parameters These parameters are set for all three methods. parameter Description default endpoint Either RDF File or SPARQL endpoint containing the ABox - owlFile The ontology (TBox) file - seed A seed for every random decision 1 types The allowed types, whereas empty or not set means every class type is allowed percentageOfPositiveExamples The percentage of positive examples which should be kept from the maxIndividualsPerExampleConcept for the learning problem 0.5 percentageOfNegativeExamples The percentage of negative examples which should be kept from the maxIndividualsPerExampleConcept for the learning problem 0.5 maxNoOfExamples At most this amount of positive (resp. negative) examples should be kept for the learning problem. 30 minNoOfExamples At least this amount of positive (resp. negative) examples should be kept for the learning problem. However if there are less individuals than the value, it will just take the individuals. 5 removeLiterals If the final TBox+ABox should be pruned from Literals and thus making the file smaller. false aboxResultRetrievalLimit An internal limit for retrieving only this amount of query solutions if the ABox is generated. This will determine how big the ABox will get. 100 splitContainment The split between training and test dataset. 0 = all problems in test, 1 = all problems in training. 0.5 = split the problems 50/50. 0.5 openWorldAssumption If the benchmark should be under the Open World Assumption. Closed World Assumption otherwise. If true will use Reasoner to assure that every problem is correct under OWA. false Use Positive and Negative Concepts Additional to the above parameters you can set the concepts. This is basically just a list of positives and negatives concepts. concepts: - positive: POSITIVE_CONCEPT negatives: - NEGATIVE_CONCEPT1 ... - positive: ... negatives ... Example endpoint: http://dbpedia.org/sparql owlFile: ./dbpedia.owl types: - http://dbpedia.org/ontology/Work - http://dbpedia.org/ontology/Band - http://dbpedia.org/ontology/MusicalArtist - http://dbpedia.org/ontology/Album - http://dbpedia.org/ontology/Actor - http://dbpedia.org/ontology/MusicGenre maxIndividualsPerExampleConcept: 30 percentageOfPositiveExamples: 0.5 percentageOfNegativeExamples: 0.5 maxNoOfExamples: 30 minNoOfExamples: 5 concepts: - positive: Band and hasAlbum some Album negatives: - not Band and hasAlbum some Album - Band and not (hasAlbum some Album) - positive: Actor and MusicalArtist negatives: - Actor and not MusicalArtist - not Actor and MusicalArtist Use Positive and Generate Negative Concepts If you want to generate negative concepts for all or just some positive concepts, just remove the negatives. concepts: - positive: POSITIVE_CONCEPT #here all negatives concepts will be generated - positive: ... #not here though negatives: ... Example endpoint: http://dbpedia.org/sparql owlFile: ./dbpedia.owl types: - http://dbpedia.org/ontology/Work - http://dbpedia.org/ontology/Band - http://dbpedia.org/ontology/MusicalArtist - http://dbpedia.org/ontology/Album - http://dbpedia.org/ontology/Actor - http://dbpedia.org/ontology/MusicGenre maxIndividualsPerExampleConcept: 30 percentageOfPositiveExamples: 0.5 percentageOfNegativeExamples: 0.5 maxNoOfExamples: 30 minNoOfExamples: 5 concepts: - positive: Band and hasAlbum some Album - positive: Actor and MusicalArtist negatives: - Actor and not MusicalArtist - not Actor and MusicalArtist Generate Positive and Negative Concepts Additional to the general parameters you can set the following parameters which indicate how to generate positive concepts parameter Description default maxGenerateConcepts The amount of concepts which should be generated (might be less) 20 maxConceptLength The maximum length a concept is allowed to be. 10 minConceptLength The minimum length a concept is allowed to be. 4 maxDepth The recursive depth on how deep a concept should be constructed 2 inferDirectSuperClasses If direct super Classes (e.g. Person for Artist) should be allowed during the construction of a concept. true namespace The namespace in which a class or rule/property has to reside in. if empty or not set all are allowed. (optional) strict Assures that every (positive and negative) concept has at least minNoOfExamples Examples. false negationMutationRatio The ratio in which negative mutation of a class expression happens. Will always add the original class expression as well. If set to 1 will always add a negated mutation. 0.0 negativeLimit Sets the Query limit for negative example retrievals. 100 positiveLimit Sets the Query limit for positive example retrievals. If set to 0 all results will be retrieved. Note that there might be still a limit if you're using a SPARQL endpoint and the endpoint sets the limit. 0 Example endpoint: /path/to/my/dataset.ttl owlFile: /path/to/my/ontology.owl seed: 123 types: #use all types maxIndividualsPerExampleConcept: 30 percentageOfPositiveExamples: 0.5 percentageOfNegativeExamples: 0.5 maxNoOfExamples: 30 minNoOfExamples: 5 maxGenerateConcepts: 10 maxConceptLength: 8 minConceptLength: 4 strict: true maxDepth: 1 endpointInfersRules: false removeLiterals: true negationMutationRatio: 0.5 namespace: http://example.org/ontology/ How to Achieve Good Examples To achieve good examples for small concepts like Artist you should allow only types which are semantically near that. A negative example with class of Animal wouldn't provide much information, thus it makes sense to allow other super types of the class Person such as Politician . Then the negative examples will be much more informative.","title":"Configuration"},{"location":"Usage/Configuration/#configuration","text":"In this section we'll explain how to configure the generation of a learning problem benchmark.","title":"Configuration"},{"location":"Usage/Configuration/#ways-to-generate-a-benchmark","text":"There are 3 main ways to generate a LP benchmark. The first one is to use a gold standard positive concept, which represents one learning problem and furthermore provide concepts which won't fit the positive concept (we call them negative concepts wrt a positive concept). This negative concept should be close to the positive one but yield other individuals. e.g. Politician and hasParents some Person can have multiple negative concepts such as not Politician and hasParents some Person and Politician and not (hasParents some Person) while the latter obv. wouldn't yield results. However, it might be a lot of work to add for all positive concepts multiple useful negative concepts. Hence, LPBenchGen can generate negative concepts out of positives, and you only provide positive concepts You can also just let LPBenchGen generate concepts from the TBox and ABox. It will first generate all possible concepts in the parameters provided by the configuration, and then check if these concepts yields enough results using the ABox.","title":"Ways to Generate a Benchmark"},{"location":"Usage/Configuration/#allowing-certain-types-to-yield-a-topical-subset-of-the-abox","text":"Further on you can add allowed Types. This will be used to only allow Individuals who have a class of this type To generate positive concepts only considering these types.","title":"Allowing certain types to yield a topical subset of the ABox."},{"location":"Usage/Configuration/#methods-of-generating-a-benchmark","text":"","title":"Methods of generating a Benchmark"},{"location":"Usage/Configuration/#general-parameters","text":"These parameters are set for all three methods. parameter Description default endpoint Either RDF File or SPARQL endpoint containing the ABox - owlFile The ontology (TBox) file - seed A seed for every random decision 1 types The allowed types, whereas empty or not set means every class type is allowed percentageOfPositiveExamples The percentage of positive examples which should be kept from the maxIndividualsPerExampleConcept for the learning problem 0.5 percentageOfNegativeExamples The percentage of negative examples which should be kept from the maxIndividualsPerExampleConcept for the learning problem 0.5 maxNoOfExamples At most this amount of positive (resp. negative) examples should be kept for the learning problem. 30 minNoOfExamples At least this amount of positive (resp. negative) examples should be kept for the learning problem. However if there are less individuals than the value, it will just take the individuals. 5 removeLiterals If the final TBox+ABox should be pruned from Literals and thus making the file smaller. false aboxResultRetrievalLimit An internal limit for retrieving only this amount of query solutions if the ABox is generated. This will determine how big the ABox will get. 100 splitContainment The split between training and test dataset. 0 = all problems in test, 1 = all problems in training. 0.5 = split the problems 50/50. 0.5 openWorldAssumption If the benchmark should be under the Open World Assumption. Closed World Assumption otherwise. If true will use Reasoner to assure that every problem is correct under OWA. false","title":"General Parameters"},{"location":"Usage/Configuration/#use-positive-and-negative-concepts","text":"Additional to the above parameters you can set the concepts. This is basically just a list of positives and negatives concepts. concepts: - positive: POSITIVE_CONCEPT negatives: - NEGATIVE_CONCEPT1 ... - positive: ... negatives ...","title":"Use Positive and Negative Concepts"},{"location":"Usage/Configuration/#example","text":"endpoint: http://dbpedia.org/sparql owlFile: ./dbpedia.owl types: - http://dbpedia.org/ontology/Work - http://dbpedia.org/ontology/Band - http://dbpedia.org/ontology/MusicalArtist - http://dbpedia.org/ontology/Album - http://dbpedia.org/ontology/Actor - http://dbpedia.org/ontology/MusicGenre maxIndividualsPerExampleConcept: 30 percentageOfPositiveExamples: 0.5 percentageOfNegativeExamples: 0.5 maxNoOfExamples: 30 minNoOfExamples: 5 concepts: - positive: Band and hasAlbum some Album negatives: - not Band and hasAlbum some Album - Band and not (hasAlbum some Album) - positive: Actor and MusicalArtist negatives: - Actor and not MusicalArtist - not Actor and MusicalArtist","title":"Example"},{"location":"Usage/Configuration/#use-positive-and-generate-negative-concepts","text":"If you want to generate negative concepts for all or just some positive concepts, just remove the negatives. concepts: - positive: POSITIVE_CONCEPT #here all negatives concepts will be generated - positive: ... #not here though negatives: ...","title":"Use Positive and Generate Negative Concepts"},{"location":"Usage/Configuration/#example_1","text":"endpoint: http://dbpedia.org/sparql owlFile: ./dbpedia.owl types: - http://dbpedia.org/ontology/Work - http://dbpedia.org/ontology/Band - http://dbpedia.org/ontology/MusicalArtist - http://dbpedia.org/ontology/Album - http://dbpedia.org/ontology/Actor - http://dbpedia.org/ontology/MusicGenre maxIndividualsPerExampleConcept: 30 percentageOfPositiveExamples: 0.5 percentageOfNegativeExamples: 0.5 maxNoOfExamples: 30 minNoOfExamples: 5 concepts: - positive: Band and hasAlbum some Album - positive: Actor and MusicalArtist negatives: - Actor and not MusicalArtist - not Actor and MusicalArtist","title":"Example"},{"location":"Usage/Configuration/#generate-positive-and-negative-concepts","text":"Additional to the general parameters you can set the following parameters which indicate how to generate positive concepts parameter Description default maxGenerateConcepts The amount of concepts which should be generated (might be less) 20 maxConceptLength The maximum length a concept is allowed to be. 10 minConceptLength The minimum length a concept is allowed to be. 4 maxDepth The recursive depth on how deep a concept should be constructed 2 inferDirectSuperClasses If direct super Classes (e.g. Person for Artist) should be allowed during the construction of a concept. true namespace The namespace in which a class or rule/property has to reside in. if empty or not set all are allowed. (optional) strict Assures that every (positive and negative) concept has at least minNoOfExamples Examples. false negationMutationRatio The ratio in which negative mutation of a class expression happens. Will always add the original class expression as well. If set to 1 will always add a negated mutation. 0.0 negativeLimit Sets the Query limit for negative example retrievals. 100 positiveLimit Sets the Query limit for positive example retrievals. If set to 0 all results will be retrieved. Note that there might be still a limit if you're using a SPARQL endpoint and the endpoint sets the limit. 0","title":"Generate Positive and Negative Concepts"},{"location":"Usage/Configuration/#example_2","text":"endpoint: /path/to/my/dataset.ttl owlFile: /path/to/my/ontology.owl seed: 123 types: #use all types maxIndividualsPerExampleConcept: 30 percentageOfPositiveExamples: 0.5 percentageOfNegativeExamples: 0.5 maxNoOfExamples: 30 minNoOfExamples: 5 maxGenerateConcepts: 10 maxConceptLength: 8 minConceptLength: 4 strict: true maxDepth: 1 endpointInfersRules: false removeLiterals: true negationMutationRatio: 0.5 namespace: http://example.org/ontology/","title":"Example"},{"location":"Usage/Configuration/#how-to-achieve-good-examples","text":"To achieve good examples for small concepts like Artist you should allow only types which are semantically near that. A negative example with class of Animal wouldn't provide much information, thus it makes sense to allow other super types of the class Person such as Politician . Then the negative examples will be much more informative.","title":"How to Achieve Good Examples"},{"location":"Usage/Develop/","text":"Develop In this section we'll explain how to use LPBenchGen as a package and use a different Concept generator Add LPBenchGen as a maven dependency Add the github repository to your pom.xml <repository> <id>lpbenchgen-github</id> <name>LPBenchGen Dice Group repository</name> <url>https://maven.pkg.github.com/dice-group/LPBenchGen</url> </repository> Now add the dependency <dependency> <groupId>org.dice_group</groupId> <artifactId>LPBenchGen</artifactId> <version>2.0.1</version> </dependency> Create a Benchmark programmatically Create a Benchmark containing of train, test and gold standard datasets as well as an ABox programmatically import org.dice_group.lpbenchgen.config.Configuration; import org.dice_group.lpbenchgen.lp.LPBenchmark; import org.dice_group.lpbenchgen.lp.LPGenerator; public class MyClass { public void createMyBenchmark() { LPGenerator generator = new LPGenerator(); Configuration conf = new Configuration(); conf.setEndpoint(\"my-abox.ttl\"); conf.setOwlFile(\"my-owl.ttl\"); boolean generateABox = true; LPBenchmark benchmark = generator.createBenchmark(conf, generateABox); //save files as rdf (also saves ABox) generator.saveLPBenchmark(benchmark, \"my-benchmark-name\", \"rdf\"); } } Use my own concept generator This is quite simple create a Java class which extends the org.dice_group.lpbenchgen.dl.OWLTBoxConceptCreator import org.dice_group.lpbenchgen.config.Configuration; import org.dice_group.lpbenchgen.config.PosNegExample; import org.dice_group.lpbenchgen.dl.Parser; import org.dice_group.lpbenchgen.sparql.IndividualRetriever; import org.semanticweb.owlapi.model.OWLOntology; import org.semanticweb.owlapi.reasoner.OWLReasoner; import java.util.Collection; import java.util.List; public class MyConceptCreator implements OWLTBoxConceptCreator { public MyConceptCreator(Configuration conf, IndividualRetriever retriever, OWLOntology ontology, List<String> allowedTypes, Parser parser, OWLReasoner res, String namespace) { //TODO initialize your creator } /** * Create distinct concepts. * * @param noOfConcepts the no of concepts * @return the concepts */ @Override public Collection<PosNegExample> createDistinctConcepts(int noOfConcepts) { //TODO create your positive and negative concepts here } /** * Returns the types which are allowed. * If inferredDirectSuperTypes is set to true, the inferred types should be added and returned here as well. * * @return all allowed types */ @Override public List<String> getAllowedTypes() { //TODO return all allowed types } } Now create a new LPGenerator extending the basic LPGenerator and Override the concept creator creation. import org.dice_group.lpbenchgen.dl.OWLTBoxConceptCreator; import org.dice_group.lpbenchgen.lp.LPGenerator; public class MyLPGenerator extends LPGenerator { @Override protected OWLTBoxConceptCreator createConceptCreator(String namespace) { return new MyConceptCreator(conf, retriever, parser.getOntology(), types, parser, res, namespace); } } Now you can use the MyLPGenerator likewise the LPGenerator and create Benchmarks using your Concept creator. JavaDoc The JavaDoc can be found at here","title":"Develop"},{"location":"Usage/Develop/#develop","text":"In this section we'll explain how to use LPBenchGen as a package and use a different Concept generator","title":"Develop"},{"location":"Usage/Develop/#add-lpbenchgen-as-a-maven-dependency","text":"Add the github repository to your pom.xml <repository> <id>lpbenchgen-github</id> <name>LPBenchGen Dice Group repository</name> <url>https://maven.pkg.github.com/dice-group/LPBenchGen</url> </repository> Now add the dependency <dependency> <groupId>org.dice_group</groupId> <artifactId>LPBenchGen</artifactId> <version>2.0.1</version> </dependency>","title":"Add LPBenchGen as a maven dependency"},{"location":"Usage/Develop/#create-a-benchmark-programmatically","text":"Create a Benchmark containing of train, test and gold standard datasets as well as an ABox programmatically import org.dice_group.lpbenchgen.config.Configuration; import org.dice_group.lpbenchgen.lp.LPBenchmark; import org.dice_group.lpbenchgen.lp.LPGenerator; public class MyClass { public void createMyBenchmark() { LPGenerator generator = new LPGenerator(); Configuration conf = new Configuration(); conf.setEndpoint(\"my-abox.ttl\"); conf.setOwlFile(\"my-owl.ttl\"); boolean generateABox = true; LPBenchmark benchmark = generator.createBenchmark(conf, generateABox); //save files as rdf (also saves ABox) generator.saveLPBenchmark(benchmark, \"my-benchmark-name\", \"rdf\"); } }","title":"Create a Benchmark programmatically"},{"location":"Usage/Develop/#use-my-own-concept-generator","text":"This is quite simple create a Java class which extends the org.dice_group.lpbenchgen.dl.OWLTBoxConceptCreator import org.dice_group.lpbenchgen.config.Configuration; import org.dice_group.lpbenchgen.config.PosNegExample; import org.dice_group.lpbenchgen.dl.Parser; import org.dice_group.lpbenchgen.sparql.IndividualRetriever; import org.semanticweb.owlapi.model.OWLOntology; import org.semanticweb.owlapi.reasoner.OWLReasoner; import java.util.Collection; import java.util.List; public class MyConceptCreator implements OWLTBoxConceptCreator { public MyConceptCreator(Configuration conf, IndividualRetriever retriever, OWLOntology ontology, List<String> allowedTypes, Parser parser, OWLReasoner res, String namespace) { //TODO initialize your creator } /** * Create distinct concepts. * * @param noOfConcepts the no of concepts * @return the concepts */ @Override public Collection<PosNegExample> createDistinctConcepts(int noOfConcepts) { //TODO create your positive and negative concepts here } /** * Returns the types which are allowed. * If inferredDirectSuperTypes is set to true, the inferred types should be added and returned here as well. * * @return all allowed types */ @Override public List<String> getAllowedTypes() { //TODO return all allowed types } } Now create a new LPGenerator extending the basic LPGenerator and Override the concept creator creation. import org.dice_group.lpbenchgen.dl.OWLTBoxConceptCreator; import org.dice_group.lpbenchgen.lp.LPGenerator; public class MyLPGenerator extends LPGenerator { @Override protected OWLTBoxConceptCreator createConceptCreator(String namespace) { return new MyConceptCreator(conf, retriever, parser.getOntology(), types, parser, res, namespace); } } Now you can use the MyLPGenerator likewise the LPGenerator and create Benchmarks using your Concept creator.","title":"Use my own concept generator"},{"location":"Usage/Develop/#javadoc","text":"The JavaDoc can be found at here","title":"JavaDoc"},{"location":"Usage/Evaluation/","text":"Evaluation In this section we'll show you how to evaluate your systems answer to a LPBenchGen benchmark. You'll need the following: Test Benchmark file (RDF/TURTLE) Corresponding Gold Standard (RDF/TURTLE) System answers in either Pertain or Includes Format (see below) IMPORTANT: To assure that the gold standard is correct and complete use positiveLimit: 0 in the benchmark generation. If you're using a SPARQL endpoint, take care that the endpoint doesn't set a Limit by itself. To start the evaluation execute the following: java -cp lpbenchgen-2.0.1.jar org.dice_group.lpbenchgen.Evaluation (--pertain-format | --includes-format) GOLD_STANDARD.ttl TEST_BENCHMARK.ttl SYSTEM_ANSWERS.ttl OUTPUT_REPORT_FILE.tsv The Benchmark will then remove all examples from the gold standard as well as from the system answers and evaluates on the remaining individuals, which weren't classified in the test benchmark. The results will be a TSV file containing for each Learning Problem the true positives, false positives, false negatives, the F1-measure, Precision and Recall. Further on it will add the Macro and Micro F1-measure, Precision and Recall. Pertain Format In this format the system has to add a result resource which pertains to the corresponding learning problem resource and adds the resources to that result resource. Further on setting a Boolean if the resources belongs to the learning problem. The pertain-format looks like the following: @prefix lpres:<https://lpbenchgen.org/resource/> @prefix lpprop:<https://lpbenchgen.org/property/> lpres:result_1 lpprop:pertainsTo lpres:lp_1; lpprop:resource test:Individual2; lpprop:resource test:Individual1; lpprop:belongsToLP true. lpres:result_2 lpprop:pertainsTo lpres:lp_1; lpprop:resource test:Individual9; lpprop:belongsToLP true. Includes Format In this format the system simply adds the resources which belongs to the learning problem using the includesResources property the same way as the test benchmark file. The includes-format looks like the following: @prefix lpres:<https://lpbenchgen.org/resource/> @prefix lpprop:<https://lpbenchgen.org/property/> lpres:lp_1 lpprop:includesResource test:Individual1, test:Individual9, test:Individual2 .","title":"Evaluation"},{"location":"Usage/Evaluation/#evaluation","text":"In this section we'll show you how to evaluate your systems answer to a LPBenchGen benchmark. You'll need the following: Test Benchmark file (RDF/TURTLE) Corresponding Gold Standard (RDF/TURTLE) System answers in either Pertain or Includes Format (see below) IMPORTANT: To assure that the gold standard is correct and complete use positiveLimit: 0 in the benchmark generation. If you're using a SPARQL endpoint, take care that the endpoint doesn't set a Limit by itself. To start the evaluation execute the following: java -cp lpbenchgen-2.0.1.jar org.dice_group.lpbenchgen.Evaluation (--pertain-format | --includes-format) GOLD_STANDARD.ttl TEST_BENCHMARK.ttl SYSTEM_ANSWERS.ttl OUTPUT_REPORT_FILE.tsv The Benchmark will then remove all examples from the gold standard as well as from the system answers and evaluates on the remaining individuals, which weren't classified in the test benchmark. The results will be a TSV file containing for each Learning Problem the true positives, false positives, false negatives, the F1-measure, Precision and Recall. Further on it will add the Macro and Micro F1-measure, Precision and Recall.","title":"Evaluation"},{"location":"Usage/Evaluation/#pertain-format","text":"In this format the system has to add a result resource which pertains to the corresponding learning problem resource and adds the resources to that result resource. Further on setting a Boolean if the resources belongs to the learning problem. The pertain-format looks like the following: @prefix lpres:<https://lpbenchgen.org/resource/> @prefix lpprop:<https://lpbenchgen.org/property/> lpres:result_1 lpprop:pertainsTo lpres:lp_1; lpprop:resource test:Individual2; lpprop:resource test:Individual1; lpprop:belongsToLP true. lpres:result_2 lpprop:pertainsTo lpres:lp_1; lpprop:resource test:Individual9; lpprop:belongsToLP true.","title":"Pertain Format"},{"location":"Usage/Evaluation/#includes-format","text":"In this format the system simply adds the resources which belongs to the learning problem using the includesResources property the same way as the test benchmark file. The includes-format looks like the following: @prefix lpres:<https://lpbenchgen.org/resource/> @prefix lpprop:<https://lpbenchgen.org/property/> lpres:lp_1 lpprop:includesResource test:Individual1, test:Individual9, test:Individual2 .","title":"Includes Format"}]}